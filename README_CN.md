# 迷你AI （AI智能）

一个革命性的轻量级AI，可完全基于CPU运行强大的AI模型 - 无需GPU！适合任何电脑，从轻薄笔记本到企业电脑。


## 核心特性

### **革命性的纯CPU AI - 无需GPU！**
- **零GPU依赖**: 仅使用CPU运行强大的大语言模型 - 无需昂贵的显卡！
- **通用兼容性**: 适用于任何电脑 - 从10年前的笔记本到现代电脑 
- **即装即用**: 无需CUDA驱动，无需GPU兼容性检查 - 安装即可运行

### **大语言模型民主化**
- **人人可用的AI**: 为每个电脑用户带来企业级AI能力
- **无硬件门槛**: 学生、研究人员和开发者无论硬件预算如何都能体验AI
- **小企业就绪**: 让小企业无需基础设施投资即可启用AI功能
- **离线智能**: 完整AI功能无需互联网依赖或云服务费用

### **完整的 Ollama 管理**
- **开机自启配置**: 自动在开机时启动 Ollama 服务
- **模型管理**: 下载、删除和管理 AI 模型
- **聊天界面**: 内置聊天界面用于测试模型

### **智能自动联网搜索 - 革命性AI增强功能！**
- **智能可信度检测**: 自动评估AI回答质量和可靠性
- **自动网络增强**: 当可信度低于70%时，自动搜索网络获取准确信息
- **实时信息获取**: 为时效性查询获取最新信息
- **无缝集成**: 网络搜索结果智能融合到AI回答中
- **无需手动干预**: 全自动化 - 只需提问即可获得增强回答
- **多源验证**: 结合多个网络来源提供全面回答


## 性能数据 - 纯CPU AI运行实证！

| 指标 | 数值 | 描述 |
|------|------|------|
| **GPU需求** | **零** | **无需显卡 - 集成显卡即可运行！** |
| **CPU支持** | 任意x64 | Intel、AMD，甚至较老处理器都能完美运行 |
| **启动时间** | <3秒 | 无需漫长GPU初始化，即时访问AI |
| **模型大小** | 0.2-2.5GB | 为CPU推理优化的紧凑而强大的模型 |
| **最低内存** | 4GB | 推荐用于大模型流畅运行 |


## 使用场景 - 纯CPU AI革命

### **适合所有没有昂贵硬件的用户:**
- **预算开发者**: 无需投资2万元GPU即可构建AI应用
- **学生和研究人员**: 在大学/个人笔记本上访问强大语言模型
- **小企业**: 经济实惠地实现AI客服、内容生成和自动化
- **内容创作者**: 仅使用现有电脑生成文章、代码和创意内容
- **教育机构**: 无需昂贵实验设备即可教授AI概念
- **远程工作者**: 随处可用的AI生产力工具，甚至离线可用
- **旧硬件用户**: 为老旧电脑注入新的AI活力
- **安静环境**: 图书馆、共享办公室、卧室 - 无噪音GPU散热

### **自动联网搜索增强:**
- **研究辅助**: 为学术论文和报告获取最新信息
- **新闻更新**: 始终获取时事的最新信息
- **技术支持**: 自动获取最新文档和解决方案
- **市场研究**: 为商业决策和分析提供实时数据
- **事实核查**: 自动通过网络来源验证信息
- **学习增强**: 获得多角度的全面回答

### **不推荐用于:**
- 大模型实时视频处理
- 从头训练新模型（仅推理）
- 需要亚秒级响应的极时敏应用


## 快速开始

### 前置要求 - 无需GPU！
- **CPU**: 任意64位处理器（Intel/AMD）- 甚至较老型号都能运行！
- **GPU**: **不需要** - 集成显卡即可满足需求
- **操作系统**: Windows 10/11 (64位)
- **运行环境**: Python 3.10 或更高版本
- **内存**: 4GB+（推荐8GB用于更大模型）
- **存储**: 5GB+ 可用磁盘空间（用于AI模型）
- **显卡**: 基础集成显卡（无需独立GPU）
- **电源**: 标准笔记本/台式机电源（无需高功率PSU）

### 安装

1. **下载 迷你AI一键安装包**
   ```bash
   MiniAISetup.exe
   ```
2. **运行应用程序**
   ```bash
   MiniAI,exe
   ```

### 首次设置

1. **下载您的第一个模型**
   - 转到"模型管理"选项卡
   - 选择一个轻量级模型 (例如 `qwen3: 0.6b)
   - 点击"下载模型"
   - 等待下载完成

2. **测试模型**
   - 切换到"聊天界面"选项卡
   - 选择您下载的模型
   - 输入消息并点击"发送"

3. **配置自动启动** (可选)
   - 切换到"开机启动"选项卡
   - 启用"开机自动启动 Ollama 服务"



## 推荐模型

| 模型 | 大小 | 使用场景 | 性能 |
|------|------|----------|------|
| `tinyllama:1.1b` | 0.6GB | 基础聊天、学习 | 快速、低资源 |
| `qwen3:0.6b` | 0.5GB | 轻量级任务 | 非常快 |
| `gemma3:1b` | 0.8GB | 通用目的 | 平衡 |
| `deepseek-r1:1.5b` | 1.1GB | 代码辅助 | 良好推理 |
| `llama3.2:1b` | 1.3GB | 代码辅助 | 良好推理 |
| `qwen3:4b` | 2.5GB | 高级聊天 | 最佳质量 |

## 配置

### 环境变量
应用程序管理这些 Ollama 环境变量:

- **OLLAMA_HOST**: 服务器地址 (默认: localhost)
- **OLLAMA_PORT**: 端口号 (默认: 11434)
- **OLLAMA_MODELS**: 模型存储路径 (默认: ~/.ollama/models)
- **OLLAMA_KEEP_ALIVE**: 模型保持活跃时间 (默认: 5m)


## 许可证

本项目采用 MIT 许可证 - 查看 [LICENSE](LICENSE) 文件了解详情。


## 支持

### 获取帮助
- Email：267278466@qq.com

---

## 致谢

**特别感谢 [Ollama 团队](https://github.com/ollama/ollama) 创造了这个令人惊叹的 AI 平台！**

本项目建立在 Ollama 的基础之上，这是一个令人难以置信的开源平台，让每个人都能在本地运行 AI 模型。没有Ollama 团队的创新工作，迷你AI 就不会存在。我们感谢他们对 AI 技术的奉献，以及让全世界的开发者和用户都能使用这项技术。


---

**MiniAI** - 让 AI 在任何 Windows 电脑上都能使用！ 🚀

*专为开发、学习和低资源环境而设计。* 
